from django.shortcuts import render
# from transformers import AutoModelForCausalLM, AutoTokenizer
# import torch

# def chat(request):
#     return render(request, 'home.html')

# ================================================================
# pip install transformers => cmdì°½ì—ì„œ install
# pip install pandas => cmdì°½ì—ì„œ install
# pip install torch => cmdì°½ì—ì„œ install
import torch
from transformers import pipeline
import pandas as pd
from transformers import TapexTokenizer, BartForConditionalGeneration
from transformers import AutoTokenizer, AutoModelForTokenClassification

import sqlite3

import json

from django.http import JsonResponse

count = 1
userResultInfo={}

# ì¢‹ì•„í•˜ëŠ” ê²ƒ ìˆœì„œëŒ€ë¡œ ë½‘ëŠ” í•¨ìˆ˜
def printFor(list) :

  result = ''
  count = 0

  for i in list :
    if count == 0 :
      result = i
    else :
      result = result + ', ' + i
    count = count + 1

  return result



def home(request):
    return render(request, 'home.html',{'count':count})



# 'ë„¤'ì„ íƒ ì‹œ ì‘ë™ë˜ëŠ” í•¨ìˆ˜
def yesAnswerFn(request) :
  # ëª¨ë¸ ì„¸íŒ…
  tokenizer = AutoTokenizer.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  model = AutoModelForTokenClassification.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  ner = pipeline("ner", model=model, tokenizer=tokenizer)
  
  count = 2

  # ê¸€ë¡œë²Œ ë³€ìˆ˜ë¡œ ì„¤ì •
  global uniData
  global conData
  global userUniInfo
  global userConInfo
  global userResultInfo

  # ì¢‹ì•„í•˜ëŠ” ê³¼ëª©
  subjectList = []
  # ì¢‹ì•„í•˜ëŠ” ê²ƒ
  hobbyList = []
  # ì²˜ìŒì¸ì§€ ì•„ë‹Œì§€
  first = True

      

  connection = sqlite3.connect('db.sqlite3')  # db.sqlite3 íŒŒì¼ì˜ ê²½ë¡œ
  cursor = connection.cursor()



  userMsg = request.GET.get('userMsg')
  ner_userAnswer = ner(userMsg)
  
  for i in ner_userAnswer :
    subjectList.append(i['word'])
    if first == True :
      cursor.execute("SELECT * FROM uniInfoTable where í•™ê³¼ like '%"+i['word']+"%'")
      userResultInfo = cursor.fetchall()
      # userResultInfo = uniData[uniData['1'].str.contains(i['word'], na = False)]
      userResultInfo = pd.DataFrame(userResultInfo)
      first = False
    else :
      # data = uniData[uniData['í•™ê³¼'].str.contains(i['word'], na = False)]
      cursor.execute("SELECT * FROM uniInfoTable where í•™ê³¼ like '%"+i['word']+"%'")
      data = cursor.fetchall()
      userResultInfo = pd.concat([userResultInfo,data])

  userResultInfo.columns = ['í•™êµ', 'í•™ê³¼', 'ë“±ë¡ê¸ˆ', 'ìœ„ì¹˜', 'ê³¼ëª©', 'ë°±ë¶„ìœ„']
  userResultInfo['ë°±ë¶„ìœ„'].astype(float)

  # ë³€ìˆ˜ ì´ˆê¸°í™”
  first = True

  # if userResultInfo.empty == True :
  #   killProcessMsg()

  return render(request, 'home.html', {'count': count})

  

# ì„±ì 
def scoreFn(request) :

  global userResultInfo

  tokenizer = AutoTokenizer.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  model = AutoModelForTokenClassification.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  ner = pipeline("ner", model=model, tokenizer=tokenizer)
  

  userMsg = request.GET.get('userMsg')
  ner_userAnswer = ner(userMsg)

  num = float(ner_userAnswer[0]['word'])
  userResultInfo = userResultInfo[userResultInfo['ë°±ë¶„ìœ„'] > num]

  # if userResultInfo.empty == True :
  #   print("í•™ìƒì˜ ì„±ì ìœ¼ë¡œëŠ” ê°ˆ ìˆ˜ ìˆëŠ” ëŒ€í•™ì´ ì—†ì–´ìš” ğŸ˜±")
  #   time.sleep(1)
  #   print("ì¡°ê¸ˆ ë” ê³µë¶€í•˜ê³  ì˜¤ì„¸ìš” ğŸ˜±")
  #   time.sleep(1)
  #   sys.exit()

  print(userResultInfo)
  return render(request, 'home.html')


# ë“±ë¡ê¸ˆ
def moneyFn(request) :

  global userResultInfo

  tokenizer = AutoTokenizer.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  model = AutoModelForTokenClassification.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  ner = pipeline("ner", model=model, tokenizer=tokenizer)
    

  userMsg = request.GET.get('userMsg')
  ner_userAnswer = ner(userMsg)

  list = []
  for i in ner_userAnswer :
    if ('##' in i['word']) == False:
      list.append(i['word'])

  money = int(list[0] + "0000")
  userResultInfo['ë“±ë¡ê¸ˆ'] = userResultInfo['ë“±ë¡ê¸ˆ'].str.replace(',', '')

  if list[1] == 'ì´ìƒ' :
    userResultInfo = userResultInfo[(userResultInfo['ë“±ë¡ê¸ˆ'].astype(int) >= money)]
  elif list[1] == 'ì´í•˜' :
    userResultInfo = userResultInfo[(userResultInfo['ë“±ë¡ê¸ˆ'].astype(int) <= money)]
  elif list[1] == 'ì´ˆê³¼' :
    userResultInfo = userResultInfo[(userResultInfo['ë“±ë¡ê¸ˆ'].astype(int) > money)]
  elif  list[1] == 'ë¯¸ë§Œ' :
    userResultInfo = userResultInfo[(userResultInfo['ë“±ë¡ê¸ˆ'].astype(int) < money)]


  # if userResultInfo.empty == True :
  #   print("ì¡°ê±´ì— ì í•©í•œ í•™êµê°€ ì—†ì–´ìš” ğŸ˜±")
  #   time.sleep(1)
  #   sys.exit()

  data = userResultInfo.to_json(orient='records')

  return JsonResponse(data, safe=False)
    


# ê±°ë¦¬
def localFn(request) :

  global userResultInfo

  tokenizer = AutoTokenizer.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  model = AutoModelForTokenClassification.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  ner = pipeline("ner", model=model, tokenizer=tokenizer)
    

  userMsg = request.GET.get('userMsg')
  ner_userAnswer = ner(userMsg)

  userResultInfo = userResultInfo[userResultInfo['ìœ„ì¹˜'].str.contains(ner_userAnswer[0]['word'], na = False)]

  # if userResultInfo.empty == True :
  #   print("ì¡°ê±´ì— ì í•©í•œ í•™êµê°€ ì—†ì–´ìš” ğŸ˜±")
  #   time.sleep(1)
  #   sys.exit()

  userResultInfo = userResultInfo.drop_duplicates()
  data = userResultInfo.to_json(orient='records')

  return JsonResponse(data, safe=False)



def likeQuestion(request) : 

  # ëª¨ë¸ ì„¸íŒ…
  tokenizer = AutoTokenizer.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  model = AutoModelForTokenClassification.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  ner = pipeline("ner", model=model, tokenizer=tokenizer)

  # ê¸€ë¡œë²Œ ë³€ìˆ˜ë¡œ ì„¤ì •
  global uniData
  global conData
  global userUniInfo
  global userConInfo
  global userResultInfo

  # ì¢‹ì•„í•˜ëŠ” ê³¼ëª©
  subjectList = []
  # ì¢‹ì•„í•˜ëŠ” ê²ƒ
  hobbyList = []
  # ì²˜ìŒì¸ì§€ ì•„ë‹Œì§€
  first = True

  connection = sqlite3.connect('db.sqlite3')  # db.sqlite3 íŒŒì¼ì˜ ê²½ë¡œ
  cursor = connection.cursor()

  userMsg = request.GET.get('userMsg')
  ner_userAnswer = ner(userMsg)

  for i in ner_userAnswer :
    subjectList.append(i['word'])
    if first == True :
      cursor.execute("SELECT * FROM uniInfoTable where ê³¼ëª© like '%"+i['word']+"%'")
      userUniInfo = cursor.fetchall()
      userUniInfo = pd.DataFrame(userUniInfo)
      first = False
    else :
      cursor.execute("SELECT * FROM uniInfoTable where ê³¼ëª© like '%"+i['word']+"%'")
      data = cursor.fetchall()
      data = pd.DataFrame(data)
      userUniInfo = pd.concat([userUniInfo,data])

  userUniInfo.columns = ['í•™êµ', 'í•™ê³¼', 'ë“±ë¡ê¸ˆ', 'ìœ„ì¹˜', 'ê³¼ëª©', 'ë°±ë¶„ìœ„']
  userUniInfo['ë°±ë¶„ìœ„'].astype(float)

  # ë³€ìˆ˜ ì´ˆê¸°í™”
  first = True

  json_data = json.dumps(subjectList)

  return JsonResponse(json_data, safe=False)


def hobbyFn(request) : 

  # ëª¨ë¸ ì„¸íŒ…
  tokenizer = AutoTokenizer.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  model = AutoModelForTokenClassification.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  ner = pipeline("ner", model=model, tokenizer=tokenizer)

  # ê¸€ë¡œë²Œ ë³€ìˆ˜ë¡œ ì„¤ì •
  global uniData
  global conData
  global userUniInfo
  global userConInfo
  global userResultInfo

  # ì¢‹ì•„í•˜ëŠ” ê³¼ëª©
  subjectList = []
  # ì¢‹ì•„í•˜ëŠ” ê²ƒ
  hobbyList = []
  # ì²˜ìŒì¸ì§€ ì•„ë‹Œì§€
  first = True

  connection = sqlite3.connect('db.sqlite3')  # db.sqlite3 íŒŒì¼ì˜ ê²½ë¡œ
  cursor = connection.cursor()

  userMsg = request.GET.get('userMsg')
  ner_userAnswer = ner(userMsg)

  cursor.execute("SELECT * FROM conInfoTable where ìƒë‹´ë‚´ì—­ like '%"+ ner_userAnswer[0]['word']+"%'")
  userConInfo = cursor.fetchall()
  
      
  userConInfo = pd.DataFrame(userConInfo)
  userConInfo.columns = ['í•™ê³¼', 'ìƒë‹´ë‚´ì—­']
  if userConInfo.empty == False :
    list = userConInfo['í•™ê³¼'].to_list()
    for i in list :
      if first == True :
        cursor.execute("SELECT * FROM uniInfoTable where í•™ê³¼ like '%"+ i +"%'")
        userResultInfo = cursor.fetchall()
        userResultInfo = pd.DataFrame(userResultInfo)
        first = False
      else :
        cursor.execute("SELECT * FROM uniInfoTable where í•™ê³¼ like '%"+ i +"%'")
        data = cursor.fetchall()
        data = pd.DataFrame(data)
        userResultInfo = pd.concat([userResultInfo,data])

    # ë³€ìˆ˜ ì´ˆê¸°í™”
    first = True
    userResultInfo.columns = ['í•™êµ', 'í•™ê³¼', 'ë“±ë¡ê¸ˆ', 'ìœ„ì¹˜', 'ê³¼ëª©', 'ë°±ë¶„ìœ„']
    userResultInfo = pd.concat([userResultInfo,userUniInfo])
    print(userResultInfo)

  else :
    userResultInfo = userUniInfo

  userResultInfo['ë°±ë¶„ìœ„'].astype(float)

  # ë³€ìˆ˜ ì´ˆê¸°í™”
  first = True

  return render(request, 'home.html')


def orderByFn(request) : 

  global userUniInfo
  global userConInfo
  global userResultInfo

  # ëª¨ë¸ ì„¸íŒ…
  tokenizer = AutoTokenizer.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  model = AutoModelForTokenClassification.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
  ner = pipeline("ner", model=model, tokenizer=tokenizer)


  userMsg = request.GET.get('userMsg')
  ner_userAnswer = ner(userMsg)

  if ner_userAnswer[0]['word'] != 'ë“±ë¡ê¸ˆ' and ner_userAnswer[0]['word'] != 'ë°±ë¶„ìœ„' :
    #userResultInfo = pd.read_json(userResultInfo)
    userResultInfo = userResultInfo.sort_values('ë°±ë¶„ìœ„')
  else :
    #userResultInfo = pd.read_json(userResultInfo)
    userResultInfo = userResultInfo.sort_values(ner_userAnswer[0]['word'])

  userResultInfo = userResultInfo.drop_duplicates()
  data = userResultInfo.head()
  data = data.to_json(orient='records')

  return JsonResponse(data, safe=False)